{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2dc67167",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Phiên bản NumPy hiện tại: 2.3.4\n",
      "Cấu hình chi tiết NumPy:\n",
      "{\n",
      "  \"Compilers\": {\n",
      "    \"c\": {\n",
      "      \"name\": \"msvc\",\n",
      "      \"linker\": \"link\",\n",
      "      \"version\": \"19.44.35217\",\n",
      "      \"commands\": \"cl\"\n",
      "    },\n",
      "    \"cython\": {\n",
      "      \"name\": \"cython\",\n",
      "      \"linker\": \"cython\",\n",
      "      \"version\": \"3.1.4\",\n",
      "      \"commands\": \"cython\"\n",
      "    },\n",
      "    \"c++\": {\n",
      "      \"name\": \"msvc\",\n",
      "      \"linker\": \"link\",\n",
      "      \"version\": \"19.44.35217\",\n",
      "      \"commands\": \"cl\"\n",
      "    }\n",
      "  },\n",
      "  \"Machine Information\": {\n",
      "    \"host\": {\n",
      "      \"cpu\": \"x86_64\",\n",
      "      \"family\": \"x86_64\",\n",
      "      \"endian\": \"little\",\n",
      "      \"system\": \"windows\"\n",
      "    },\n",
      "    \"build\": {\n",
      "      \"cpu\": \"x86_64\",\n",
      "      \"family\": \"x86_64\",\n",
      "      \"endian\": \"little\",\n",
      "      \"system\": \"windows\"\n",
      "    }\n",
      "  },\n",
      "  \"Build Dependencies\": {\n",
      "    \"blas\": {\n",
      "      \"name\": \"scipy-openblas\",\n",
      "      \"found\": true,\n",
      "      \"version\": \"0.3.30\",\n",
      "      \"detection method\": \"pkgconfig\",\n",
      "      \"include directory\": \"C:/Users/runneradmin/AppData/Local/Temp/cibw-run-0fv2o5t8/cp313-win_amd64/build/venv/Lib/site-packages/scipy_openblas64/include\",\n",
      "      \"lib directory\": \"C:/Users/runneradmin/AppData/Local/Temp/cibw-run-0fv2o5t8/cp313-win_amd64/build/venv/Lib/site-packages/scipy_openblas64/lib\",\n",
      "      \"openblas configuration\": \"OpenBLAS 0.3.30  USE64BITINT DYNAMIC_ARCH NO_AFFINITY Haswell MAX_THREADS=24\",\n",
      "      \"pc file directory\": \"D:/a/numpy-release/numpy-release/.openblas\"\n",
      "    },\n",
      "    \"lapack\": {\n",
      "      \"name\": \"scipy-openblas\",\n",
      "      \"found\": true,\n",
      "      \"version\": \"0.3.30\",\n",
      "      \"detection method\": \"pkgconfig\",\n",
      "      \"include directory\": \"C:/Users/runneradmin/AppData/Local/Temp/cibw-run-0fv2o5t8/cp313-win_amd64/build/venv/Lib/site-packages/scipy_openblas64/include\",\n",
      "      \"lib directory\": \"C:/Users/runneradmin/AppData/Local/Temp/cibw-run-0fv2o5t8/cp313-win_amd64/build/venv/Lib/site-packages/scipy_openblas64/lib\",\n",
      "      \"openblas configuration\": \"OpenBLAS 0.3.30  USE64BITINT DYNAMIC_ARCH NO_AFFINITY Haswell MAX_THREADS=24\",\n",
      "      \"pc file directory\": \"D:/a/numpy-release/numpy-release/.openblas\"\n",
      "    }\n",
      "  },\n",
      "  \"Python Information\": {\n",
      "    \"path\": \"C:\\\\Users\\\\runneradmin\\\\AppData\\\\Local\\\\Temp\\\\build-env-x2rtzeej\\\\Scripts\\\\python.exe\",\n",
      "    \"version\": \"3.13\"\n",
      "  },\n",
      "  \"SIMD Extensions\": {\n",
      "    \"baseline\": [\n",
      "      \"SSE\",\n",
      "      \"SSE2\",\n",
      "      \"SSE3\"\n",
      "    ],\n",
      "    \"found\": [\n",
      "      \"SSSE3\",\n",
      "      \"SSE41\",\n",
      "      \"POPCNT\",\n",
      "      \"SSE42\",\n",
      "      \"AVX\",\n",
      "      \"F16C\",\n",
      "      \"FMA3\",\n",
      "      \"AVX2\"\n",
      "    ],\n",
      "    \"not found\": [\n",
      "      \"AVX512F\",\n",
      "      \"AVX512CD\",\n",
      "      \"AVX512_SKX\",\n",
      "      \"AVX512_CLX\",\n",
      "      \"AVX512_CNL\",\n",
      "      \"AVX512_ICL\"\n",
      "    ]\n",
      "  }\n",
      "}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\HOANG MINH\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\numpy\\__config__.py:155: UserWarning: Install `pyyaml` for better output\n",
      "  warnings.warn(\"Install `pyyaml` for better output\", stacklevel=1)\n"
     ]
    }
   ],
   "source": [
    "# Bài 3.1:\n",
    "import numpy as np\n",
    "\n",
    "print(\"Phiên bản NumPy hiện tại:\", np.__version__)\n",
    "print(\"Cấu hình chi tiết NumPy:\")\n",
    "np.show_config()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "93e32f3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mảng arr: [0 1 2 3 4 5 6 7 8 9]\n",
      "Kích thước mảng: (10,)\n",
      "Các phần tử chẵn: [0 2 4 6 8]\n",
      "Các phần tử lẻ: [1 3 5 7 9]\n",
      "Mảng sau khi cập nhật: [  0 100   2 300   4 500   6 700   8 900]\n"
     ]
    }
   ],
   "source": [
    "#3.2\n",
    "import numpy as np\n",
    "arr = np.arange(10)\n",
    "print(\"Mảng arr:\", arr)\n",
    "print(\"Kích thước mảng:\", arr.shape)\n",
    "\n",
    "arr_even = arr[arr % 2 == 0]\n",
    "print(\"Các phần tử chẵn:\", arr_even)\n",
    "\n",
    "arr_odd = arr[arr % 2 == 1]\n",
    "print(\"Các phần tử lẻ:\", arr_odd)\n",
    "\n",
    "arr_update = np.where(arr % 2 == 0, arr, arr * 100)\n",
    "print(\"Mảng sau khi cập nhật:\", arr_update)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6fac95f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Các phần tử có trong cả hai mảng: [2]\n",
      "Phần tử chỉ có trong arr_a: [1 3 4 5 6]\n",
      "Các phần tử trong khoảng [5,10): [6 9 8 6]\n"
     ]
    }
   ],
   "source": [
    "#3.3\n",
    "import numpy as np\n",
    "\n",
    "arr_a = np.array([1,2,3,2,3,4,5,4,6])\n",
    "arr_b = np.array([7,2,10,2,9,9,8,9,8])\n",
    "\n",
    "arr_c = np.intersect1d(arr_a, arr_b)\n",
    "print(\"Các phần tử có trong cả hai mảng:\", arr_c)\n",
    "\n",
    "arr_d = np.setdiff1d(arr_a, arr_b)\n",
    "print(\"Phần tử chỉ có trong arr_a:\", arr_d)\n",
    "\n",
    "arr_f = np.array([2, 6, 9, 10, 3, 27, 8, 6, 25, 16])\n",
    "arr_e = arr_f[(arr_f >= 5) & (arr_f < 10)]\n",
    "print(\"Các phần tử trong khoảng [5,10):\", arr_e)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4cb3c30c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Câu 1  zero_arr: [0 0 0 0 1 0 0 0 0 0] \n",
      "\n",
      "Câu 2  arr_h: [10 11 12 13 14 15 16 17 18 19 20 21 22 23 24]\n",
      "Câu 2  arr_h đảo ngược: [24 23 22 21 20 19 18 17 16 15 14 13 12 11 10] \n",
      "\n",
      "Câu 3  arr_k: [1 2 0 8 2 0 1 3 0 5 0]\n",
      "Câu 3  arr_l (lọc bỏ phần tử 0): [1 2 8 2 1 3 5] \n",
      "\n",
      "Câu 4  arr_l_extended: [ 1  2  8  2  1  3  5 10 20] \n",
      "\n",
      "Câu 5  arr_inserted: [  1   2   8   2   1 100   3   5  10  20] \n",
      "\n",
      "Câu 6  arr_deleted (sau khi xóa index 0,1,2): [  2   1 100   3   5  10  20] \n",
      "\n",
      "=== KẾT QUẢ TỔNG HỢP ===\n",
      "arr ban đầu: [1 2 0 8 2 0 1 3 0 5 0]\n",
      "arr sau các bước: [  2   1 100   3   5  10  20]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# BÀI 3.4\n",
    "\n",
    "import numpy as np\n",
    "#c1\n",
    "zero_arr = np.zeros(10, dtype=int)\n",
    "zero_arr[4] = 1  \n",
    "print(\"Câu 1  zero_arr:\", zero_arr, \"\\n\")\n",
    "#c2\n",
    "arr_h = np.arange(10, 25)\n",
    "print(\"Câu 2  arr_h:\", arr_h)\n",
    "print(\"Câu 2  arr_h đảo ngược:\", arr_h[::-1], \"\\n\")\n",
    "\n",
    "#c3\n",
    "arr_k = np.array([1, 2, 0, 8, 2, 0, 1, 3, 0, 5, 0])\n",
    "arr_l = arr_k[arr_k != 0]\n",
    "print(\"Câu 3  arr_k:\", arr_k)\n",
    "print(\"Câu 3  arr_l (lọc bỏ phần tử 0):\", arr_l, \"\\n\")\n",
    "\n",
    "#c4\n",
    "arr_l_extended = np.append(arr_l, [10, 20])\n",
    "print(\"Câu 4  arr_l_extended:\", arr_l_extended, \"\\n\")\n",
    "\n",
    "#c5\n",
    "arr_inserted = np.insert(arr_l_extended, 5, 100)\n",
    "print(\"Câu 5  arr_inserted:\", arr_inserted, \"\\n\")\n",
    "\n",
    "#c6\n",
    "arr_deleted = np.delete(arr_inserted, [0, 1, 2])\n",
    "print(\"Câu 6  arr_deleted (sau khi xóa index 0,1,2):\", arr_deleted, \"\\n\")\n",
    "\n",
    "\n",
    "print(\"=== KẾT QUẢ TỔNG HỢP ===\")\n",
    "print(\"arr ban đầu:\", arr_k)\n",
    "print(\"arr sau các bước:\", arr_deleted)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "03f8bb4c",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'heights_1.txt'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mFileNotFoundError\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[3]\u001b[39m\u001b[32m, line 5\u001b[39m\n\u001b[32m      2\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnumpy\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnp\u001b[39;00m\n\u001b[32m      4\u001b[39m \u001b[38;5;66;03m# --- 1. Đọc dữ liệu từ file ---\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m5\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mheights_1.txt\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[32m      6\u001b[39m     height_list = [\u001b[38;5;28mfloat\u001b[39m(x) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m f.read().split()]\n\u001b[32m      7\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mweights_1.txt\u001b[39m\u001b[33m\"\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Roaming\\Python\\Python313\\site-packages\\IPython\\core\\interactiveshell.py:343\u001b[39m, in \u001b[36m_modified_open\u001b[39m\u001b[34m(file, *args, **kwargs)\u001b[39m\n\u001b[32m    336\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m file \u001b[38;5;129;01min\u001b[39;00m {\u001b[32m0\u001b[39m, \u001b[32m1\u001b[39m, \u001b[32m2\u001b[39m}:\n\u001b[32m    337\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m    338\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mIPython won\u001b[39m\u001b[33m'\u001b[39m\u001b[33mt let you open fd=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfile\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m by default \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    339\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mas it is likely to crash IPython. If you know what you are doing, \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    340\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33myou can use builtins\u001b[39m\u001b[33m'\u001b[39m\u001b[33m open.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    341\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m343\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mio_open\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[31mFileNotFoundError\u001b[39m: [Errno 2] No such file or directory: 'heights_1.txt'"
     ]
    }
   ],
   "source": [
    "#3.5\n",
    "import numpy as np\n",
    "\n",
    "# --- 1. Đọc dữ liệu từ file ---\n",
    "with open(\"heights_1.txt\") as f:\n",
    "    height_list = [float(x) for x in f.read().split()]\n",
    "with open(\"weights_1.txt\") as f:\n",
    "    weight_list = [float(x) for x in f.read().split()]\n",
    "\n",
    "# --- 2. Tạo array ---\n",
    "arr_height = np.array(height_list)\n",
    "arr_weight = np.array(weight_list)\n",
    "\n",
    "print(\"Chiều cao (inch):\", arr_height[:10])\n",
    "print(\"Cân nặng (pound):\", arr_weight[:10])\n",
    "\n",
    "# --- 3. Đổi đơn vị ---\n",
    "arr_height_m = arr_height * 0.0254   # inch → mét\n",
    "arr_weight_kg = arr_weight * 0.453592  # pound → kg\n",
    "\n",
    "# --- 4. Tính BMI ---\n",
    "arr_bmi = arr_weight_kg / (arr_height_m ** 2)\n",
    "\n",
    "# --- 5. Hiển thị một vài giá trị ---\n",
    "print(\"\\n5 giá trị BMI đầu tiên:\", np.round(arr_bmi[:5], 2))\n",
    "\n",
    "# --- 6. Lọc BMI ---\n",
    "arr_bmi_low = arr_bmi[arr_bmi <= 21]\n",
    "arr_bmi_high = arr_bmi[arr_bmi > 21]\n",
    "\n",
    "print(f\"\\nSố cầu thủ BMI ≤ 21: {len(arr_bmi_low)}\")\n",
    "print(f\"Số cầu thủ BMI > 21: {len(arr_bmi_high)}\")\n",
    "\n",
    "# --- 7. Tính thống kê ---\n",
    "mean_height = np.mean(arr_height_m)\n",
    "mean_weight = np.mean(arr_weight_kg)\n",
    "mean_bmi = np.mean(arr_bmi)\n",
    "\n",
    "print(f\"\\nChiều cao TB: {mean_height:.2f} m\")\n",
    "print(f\"Cân nặng TB: {mean_weight:.2f} kg\")\n",
    "print(f\"BMI TB: {mean_bmi:.2f}\")\n",
    "\n",
    "# --- 8. Tìm giá trị lớn nhất & nhỏ nhất ---\n",
    "print(f\"\\nChiều cao lớn nhất: {arr_height_m.max():.2f} m\")\n",
    "print(f\"Chiều cao nhỏ nhất: {arr_height_m.min():.2f} m\")\n",
    "print(f\"Cân nặng lớn nhất: {arr_weight_kg.max():.2f} kg\")\n",
    "print(f\"Cân nặng nhỏ nhất: {arr_weight_kg.min():.2f} kg\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "94a3b1e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Đang cố gắng đọc dữ liệu từ link: http://wiki.stat.ucla.edu/soc/index.php/SOCR_Data_MLB_HeightsWeights\n",
      "\n",
      "LỖI: Cần cài đặt pandas và lxml.\n",
      "Chạy lệnh: pip install pandas lxml\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os # Dùng để kiểm tra file tồn tại\n",
    "\n",
    "# --- GIAI ĐOẠN 1: TRÍCH XUẤT DỮ LIỆU TỪ LINK WEB BẰNG PANDAS ---\n",
    "\n",
    "# Link trang web chứa dữ liệu\n",
    "url = \"http://wiki.stat.ucla.edu/soc/index.php/SOCR_Data_MLB_HeightsWeights\"\n",
    "file_heights = \"height_1.txt\"\n",
    "file_weights = \"weight_1.txt\"\n",
    "\n",
    "print(f\"Đang cố gắng đọc dữ liệu từ link: {url}\\n\")\n",
    "\n",
    "try:\n",
    "    # Pandas có thể đọc bảng HTML trực tiếp từ link\n",
    "    # [0] nghĩa là lấy bảng (table) đầu tiên tìm thấy trên trang\n",
    "    tables = pd.read_html(url)\n",
    "    df = tables[0]\n",
    "\n",
    "    print(\"--- Đọc dữ liệu web thành công ---\")\n",
    "    print(\"5 dòng dữ liệu đầu tiên trích xuất được:\")\n",
    "    print(df.head())\n",
    "    print(\"-----------------------------------\")\n",
    "\n",
    "    # Lấy dữ liệu từ các cột \"Height(Inches)\" và \"Weight(Pounds)\"\n",
    "    height_data = df[\"Height(Inches)\"]\n",
    "    weight_data = df[\"Weight(Pounds)\"]\n",
    "\n",
    "    # --- GIAI ĐOẠN 2: GHI DỮ LIỆU RA FILE TXT ---\n",
    "    \n",
    "    # Ghi file heights.txt\n",
    "    # np.savetxt là cách nhanh để lưu 1 array/series vào file text\n",
    "    np.savetxt(file_heights, height_data, fmt='%.2f')\n",
    "    print(f\"\\nĐã ghi dữ liệu chiều cao vào file '{file_heights}'\")\n",
    "\n",
    "    # Ghi file weights.txt\n",
    "    np.savetxt(file_weights, weight_data, fmt='%.2f')\n",
    "    print(f\"Đã ghi dữ liệu cân nặng vào file '{file_weights}'\")\n",
    "\n",
    "    # --- GIAI ĐOẠN 3: HOÀN THÀNH BÀI 3.5 BẰNG NUMPY ---\n",
    "    \n",
    "    print(\"\\n--- BẮT ĐẦU GIẢI BÀI 3.5 ---\")\n",
    "    \n",
    "    # 1. Tạo numpy array arr_height từ list height (đọc từ file)\n",
    "    arr_height = np.loadtxt(file_heights)\n",
    "    print(\"1. Array chiều cao (arr_height):\")\n",
    "    print(arr_height)\n",
    "\n",
    "    # 2. Tạo numpy array arr_weight từ list weight (đọc từ file)\n",
    "    arr_weight = np.loadtxt(file_weights)\n",
    "    print(\"\\n2. Array cân nặng (arr_weight):\")\n",
    "    print(arr_weight)\n",
    "    \n",
    "    print(\"\\n--- HOÀN THÀNH ---\")\n",
    "\n",
    "except ImportError:\n",
    "    print(\"LỖI: Cần cài đặt pandas và lxml.\")\n",
    "    print(\"Chạy lệnh: pip install pandas lxml\")\n",
    "except ConnectionError:\n",
    "    print(f\"LỖI: Không thể kết nối tới link. Kiểm tra lại Internet.\")\n",
    "except Exception as e:\n",
    "    print(f\"Đã xảy ra lỗi: {e}\")\n",
    "    print(\"Vui lòng kiểm tra lại link hoặc thư viện.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "68e218c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C1 arr_true:\n",
      " [[ True  True  True]\n",
      " [ True  True  True]\n",
      " [ True  True  True]]\n",
      "C2 arr_2D original:\n",
      " [[0 1 2]\n",
      " [3 4 5]\n",
      " [6 7 8]]\n",
      "   after swapping col1 and col3:\n",
      " [[2 1 0]\n",
      " [5 4 3]\n",
      " [8 7 6]]\n",
      "   swapped back:\n",
      " [[0 1 2]\n",
      " [3 4 5]\n",
      " [6 7 8]]\n",
      "C3 after swapping row1 and row2:\n",
      " [[3 4 5]\n",
      " [0 1 2]\n",
      " [6 7 8]]\n",
      "C4 reverse rows:\n",
      " [[6 7 8]\n",
      " [3 4 5]\n",
      " [0 1 2]]\n",
      "C5 reverse columns of previous:\n",
      " [[8 7 6]\n",
      " [5 4 3]\n",
      " [2 1 0]]\n",
      "C6 arr_2D_null:\n",
      " [[ 1.  2.  3.]\n",
      " [nan  5.  6.]\n",
      " [ 7. nan  9.]]\n",
      "   has any NaN? True\n",
      "C7 arr_no_null (NaN->0):\n",
      " [[1. 2. 3.]\n",
      " [0. 5. 6.]\n",
      " [7. 0. 9.]]\n"
     ]
    }
   ],
   "source": [
    "# BAI 3.6 - thao tac tren mang 2D\n",
    "import numpy as np\n",
    "\n",
    "def bai_3_6():\n",
    "    # 1) array 3x3 True\n",
    "    arr_true = np.full((3,3), True, dtype=bool)\n",
    "    print(\"C1 arr_true:\\n\", arr_true)\n",
    "\n",
    "    # 2) arr_1D -> arr_2D 3x3 then chuyển cột 1 <-> cột 3 và ngược lại\n",
    "    arr_1D = np.arange(9)  # 0..8\n",
    "    arr_2D = arr_1D.reshape((3,3))\n",
    "    print(\"C2 arr_2D original:\\n\", arr_2D)\n",
    "    arr_swap_cols = arr_2D.copy()\n",
    "    arr_swap_cols[:, [0,2]] = arr_swap_cols[:, [2,0]]  # swap col0 & col2\n",
    "    print(\"   after swapping col1 and col3:\\n\", arr_swap_cols)\n",
    "    # swap back\n",
    "    arr_swap_cols[:, [0,2]] = arr_swap_cols[:, [2,0]]\n",
    "    print(\"   swapped back:\\n\", arr_swap_cols)\n",
    "\n",
    "    # 3) từ arr_2D, chuyển hàng 1 sang hàng 2 và ngược lại (swap row0 & row1)\n",
    "    arr_swap_rows = arr_2D.copy()\n",
    "    arr_swap_rows[[0,1], :] = arr_swap_rows[[1,0], :]\n",
    "    print(\"C3 after swapping row1 and row2:\\n\", arr_swap_rows)\n",
    "\n",
    "    # 4) đảo ngược các dòng của arr_2D (reverse row order)\n",
    "    arr_rev_rows = arr_2D[::-1, :]\n",
    "    print(\"C4 reverse rows:\\n\", arr_rev_rows)\n",
    "\n",
    "    # 5) từ arr_2D của câu 4, đảo ngược các cột (mirror horizontally)\n",
    "    arr_rev_rows_cols = arr_rev_rows[:, ::-1]\n",
    "    print(\"C5 reverse columns of previous:\\n\", arr_rev_rows_cols)\n",
    "\n",
    "    # 6) tạo arr_2D_null có NaN, kiểm tra giá trị null?\n",
    "    arr_2D_null = np.array([[1,2,3], [np.nan, 5, 6], [7, np.nan, 9]], dtype=float)\n",
    "    has_null = np.isnan(arr_2D_null).any()\n",
    "    print(\"C6 arr_2D_null:\\n\", arr_2D_null)\n",
    "    print(\"   has any NaN?\", has_null)\n",
    "\n",
    "    # 7) thay NaN bằng 0\n",
    "    arr_no_null = np.nan_to_num(arr_2D_null, nan=0.0)\n",
    "    print(\"C7 arr_no_null (NaN->0):\\n\", arr_no_null)\n",
    "\n",
    "    return {\n",
    "        \"arr_true\": arr_true, \"arr_2D\": arr_2D, \"arr_swap_cols\": arr_swap_cols,\n",
    "        \"arr_swap_rows\": arr_swap_rows, \"arr_rev_rows\": arr_rev_rows,\n",
    "        \"arr_rev_rows_cols\": arr_rev_rows_cols, \"arr_2D_null\": arr_2D_null,\n",
    "        \"arr_no_null\": arr_no_null\n",
    "    }\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    bai_3_6()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "41c86dd9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "np_baseball shape: (0,) dtype: float64\n",
      "Không có row 50 (dữ liệu ít).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HOANG MINH\\AppData\\Local\\Temp\\ipykernel_17464\\3634388120.py:8: UserWarning: loadtxt: input contained no data: \"baseball_2D.txt\"\n",
      "  data = np.loadtxt(filename, delimiter=None)\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "too many indices for array: array is 1-dimensional, but 2 were indexed",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mIndexError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[9]\u001b[39m\u001b[32m, line 63\u001b[39m\n\u001b[32m     56\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m {\n\u001b[32m     57\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mnp_baseball\u001b[39m\u001b[33m\"\u001b[39m: np_baseball, \u001b[33m\"\u001b[39m\u001b[33mnp_weight\u001b[39m\u001b[33m\"\u001b[39m: np_weight,\n\u001b[32m     58\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mheight_124\u001b[39m\u001b[33m\"\u001b[39m: height_124, \u001b[33m\"\u001b[39m\u001b[33mmean_height\u001b[39m\u001b[33m\"\u001b[39m: mean_height,\n\u001b[32m     59\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mmean_weight\u001b[39m\u001b[33m\"\u001b[39m: mean_weight, \u001b[33m\"\u001b[39m\u001b[33mcorrcoef\u001b[39m\u001b[33m\"\u001b[39m: corrcoef\n\u001b[32m     60\u001b[39m     }\n\u001b[32m     62\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[34m__name__\u001b[39m == \u001b[33m\"\u001b[39m\u001b[33m__main__\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m---> \u001b[39m\u001b[32m63\u001b[39m     \u001b[43mbai_3_7\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[9]\u001b[39m\u001b[32m, line 27\u001b[39m, in \u001b[36mbai_3_7\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m     24\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mKhông có row 50 (dữ liệu ít).\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     26\u001b[39m \u001b[38;5;66;03m# 3) tạo np_weight từ cột 2\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m27\u001b[39m np_weight = \u001b[43mnp_baseball\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[32m     28\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mnp_weight (first 10):\u001b[39m\u001b[33m\"\u001b[39m, np_weight[:\u001b[32m10\u001b[39m])\n\u001b[32m     30\u001b[39m \u001b[38;5;66;03m# 4) chiều cao vận động viên thứ 124 (index 123)\u001b[39;00m\n",
      "\u001b[31mIndexError\u001b[39m: too many indices for array: array is 1-dimensional, but 2 were indexed"
     ]
    }
   ],
   "source": [
    "# BAI 3.7 - thao tac tren baseball_2D\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "def read_baseball_2d(filename=\"baseball_2D.txt\"):\n",
    "    if os.path.exists(filename):\n",
    "        # giả sử file text: mỗi dòng 2 số (height inch, weight pounds) tách bởi space/comma\n",
    "        data = np.loadtxt(filename, delimiter=None)\n",
    "        return data\n",
    "    # nếu không có file, tạo sample (200 x 2)\n",
    "    np.random.seed(1)\n",
    "    heights = 68 + np.random.randint(-6,7,size=200)  # inch\n",
    "    weights = 170 + np.random.randint(-35,36,size=200)  # lbs\n",
    "    return np.column_stack((heights, weights)).astype(float)\n",
    "\n",
    "def bai_3_7():\n",
    "    np_baseball = read_baseball_2d()\n",
    "    print(\"np_baseball shape:\", np_baseball.shape, \"dtype:\", np_baseball.dtype)\n",
    "\n",
    "    # 2) in dòng thứ 50 (index 49) nếu có\n",
    "    if np_baseball.shape[0] >= 50:\n",
    "        print(\"Row 50:\", np_baseball[49])\n",
    "    else:\n",
    "        print(\"Không có row 50 (dữ liệu ít).\")\n",
    "\n",
    "    # 3) tạo np_weight từ cột 2\n",
    "    np_weight = np_baseball[:, 1]\n",
    "    print(\"np_weight (first 10):\", np_weight[:10])\n",
    "\n",
    "    # 4) chiều cao vận động viên thứ 124 (index 123)\n",
    "    if np_baseball.shape[0] >= 124:\n",
    "        height_124 = np_baseball[123, 0]\n",
    "        print(\"Height of athlete #124:\", height_124)\n",
    "    else:\n",
    "        height_124 = None\n",
    "        print(\"Không có athlete #124 trong dữ liệu mẫu.\")\n",
    "\n",
    "    # 5) trung bình chiều cao và cân nặng\n",
    "    mean_height = np.mean(np_baseball[:, 0])\n",
    "    mean_weight = np.mean(np_baseball[:, 1])\n",
    "    print(\"Mean height (inch):\", mean_height, \"Mean weight (lbs):\", mean_weight)\n",
    "\n",
    "    # 6) nhận xét tương quan: tính hệ số tương quan Pearson\n",
    "    corrcoef = np.corrcoef(np_baseball[:,0], np_baseball[:,1])[0,1]\n",
    "    print(\"Correlation coefficient (height vs weight):\", corrcoef)\n",
    "    if corrcoef > 0.5:\n",
    "        comment = \"tương quan thuận mạnh\"\n",
    "    elif corrcoef > 0.2:\n",
    "        comment = \"tương quan thuận vừa phải\"\n",
    "    elif corrcoef > -0.2:\n",
    "        comment = \"không có tương quan mạnh (gần 0)\"\n",
    "    else:\n",
    "        comment = \"tương quan nghịch\"\n",
    "    print(\"Nhận xét:\", comment)\n",
    "\n",
    "    return {\n",
    "        \"np_baseball\": np_baseball, \"np_weight\": np_weight,\n",
    "        \"height_124\": height_124, \"mean_height\": mean_height,\n",
    "        \"mean_weight\": mean_weight, \"corrcoef\": corrcoef\n",
    "    }\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    bai_3_7()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f65805a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# BAI 3.8 - trung binh height theo position\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "def bai_3_8():\n",
    "    # Nếu có file positions.txt (mỗi dòng 1 vị trí phù hợp với np_baseball), đọc vào.\n",
    "    # Nếu không có, giả lập positions cho dữ liệu mẫu 200 người.\n",
    "    pos_file = \"positions.txt\"\n",
    "    if os.path.exists(pos_file):\n",
    "        with open(pos_file) as f:\n",
    "            positions = [line.strip() for line in f if line.strip()]\n",
    "        positions = np.array(positions)\n",
    "        print(\"Đã đọc positions từ file.\")\n",
    "    else:\n",
    "        # giả lập: sample positions: 'P','C','1B','2B','3B','SS','LF','CF','RF'\n",
    "        sample_positions = ['P','C','1B','2B','3B','SS','LF','CF','RF']\n",
    "        # tạo 200 positions ngẫu nhiên\n",
    "        np.random.seed(2)\n",
    "        positions = np.random.choice(sample_positions, size=200)\n",
    "        print(\"Không có file positions -> dùng positions mẫu.\")\n",
    "\n",
    "    # cần heights tương ứng (dùng hàm read_baseball_2d ở trên nếu có)\n",
    "    if os.path.exists(\"baseball_2D.txt\"):\n",
    "        data = np.loadtxt(\"baseball_2D.txt\")\n",
    "        heights = data[:,0]\n",
    "    else:\n",
    "        # tạo heights giống phần trước (200)\n",
    "        np.random.seed(1)\n",
    "        heights = (68 + np.random.randint(-6,7,size=200)).astype(float)\n",
    "\n",
    "    # tính mean height theo position\n",
    "    unique_pos = np.unique(positions)\n",
    "    mean_by_pos = {}\n",
    "    for p in unique_pos:\n",
    "        mask = positions == p\n",
    "        if np.any(mask):\n",
    "            mean_by_pos[p] = float(np.mean(heights[mask]))\n",
    "        else:\n",
    "            mean_by_pos[p] = None\n",
    "\n",
    "    print(\"Mean height by position:\")\n",
    "    for p, m in sorted(mean_by_pos.items()):\n",
    "        print(f\"  {p}: {m:.2f} inch\" if m is not None else f\"  {p}: None\")\n",
    "\n",
    "    return mean_by_pos\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    bai_3_8()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "09a9dfb6",
   "metadata": {},
   "outputs": [
    {
     "ename": "HTTPError",
     "evalue": "HTTP Error 404: Not Found",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mHTTPError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[11]\u001b[39m\u001b[32m, line 10\u001b[39m\n\u001b[32m      7\u001b[39m url = \u001b[33m'\u001b[39m\u001b[33mhttps://raw.githubusercontent.com/guipsamora/pandas_exercises/master/02_Filtering_\u001b[39m\u001b[33m%\u001b[39m\u001b[33m26_Sorting/Euro_2012/Euro_2012_stats.csv\u001b[39m\u001b[33m'\u001b[39m\n\u001b[32m      9\u001b[39m \u001b[38;5;66;03m# \"Tạo data frame euro12\" (Đọc file)\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m10\u001b[39m euro12 = \u001b[43mpd\u001b[49m\u001b[43m.\u001b[49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[43murl\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     11\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33m--- Đã đọc dữ liệu euro2012.csv ---\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     14\u001b[39m \u001b[38;5;66;03m# 1. In giá trị cột Goals\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\HOANG MINH\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1026\u001b[39m, in \u001b[36mread_csv\u001b[39m\u001b[34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[39m\n\u001b[32m   1013\u001b[39m kwds_defaults = _refine_defaults_read(\n\u001b[32m   1014\u001b[39m     dialect,\n\u001b[32m   1015\u001b[39m     delimiter,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1022\u001b[39m     dtype_backend=dtype_backend,\n\u001b[32m   1023\u001b[39m )\n\u001b[32m   1024\u001b[39m kwds.update(kwds_defaults)\n\u001b[32m-> \u001b[39m\u001b[32m1026\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\HOANG MINH\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:620\u001b[39m, in \u001b[36m_read\u001b[39m\u001b[34m(filepath_or_buffer, kwds)\u001b[39m\n\u001b[32m    617\u001b[39m _validate_names(kwds.get(\u001b[33m\"\u001b[39m\u001b[33mnames\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[32m    619\u001b[39m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m620\u001b[39m parser = \u001b[43mTextFileReader\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    622\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[32m    623\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\HOANG MINH\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1620\u001b[39m, in \u001b[36mTextFileReader.__init__\u001b[39m\u001b[34m(self, f, engine, **kwds)\u001b[39m\n\u001b[32m   1617\u001b[39m     \u001b[38;5;28mself\u001b[39m.options[\u001b[33m\"\u001b[39m\u001b[33mhas_index_names\u001b[39m\u001b[33m\"\u001b[39m] = kwds[\u001b[33m\"\u001b[39m\u001b[33mhas_index_names\u001b[39m\u001b[33m\"\u001b[39m]\n\u001b[32m   1619\u001b[39m \u001b[38;5;28mself\u001b[39m.handles: IOHandles | \u001b[38;5;28;01mNone\u001b[39;00m = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1620\u001b[39m \u001b[38;5;28mself\u001b[39m._engine = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_make_engine\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mengine\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\HOANG MINH\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1880\u001b[39m, in \u001b[36mTextFileReader._make_engine\u001b[39m\u001b[34m(self, f, engine)\u001b[39m\n\u001b[32m   1878\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mb\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[32m   1879\u001b[39m         mode += \u001b[33m\"\u001b[39m\u001b[33mb\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m-> \u001b[39m\u001b[32m1880\u001b[39m \u001b[38;5;28mself\u001b[39m.handles = \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1881\u001b[39m \u001b[43m    \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1882\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1883\u001b[39m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mencoding\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1884\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mcompression\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1885\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmemory_map\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmemory_map\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1886\u001b[39m \u001b[43m    \u001b[49m\u001b[43mis_text\u001b[49m\u001b[43m=\u001b[49m\u001b[43mis_text\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1887\u001b[39m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mencoding_errors\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstrict\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1888\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstorage_options\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1889\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1890\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m.handles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1891\u001b[39m f = \u001b[38;5;28mself\u001b[39m.handles.handle\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\HOANG MINH\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\pandas\\io\\common.py:728\u001b[39m, in \u001b[36mget_handle\u001b[39m\u001b[34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[39m\n\u001b[32m    725\u001b[39m     codecs.lookup_error(errors)\n\u001b[32m    727\u001b[39m \u001b[38;5;66;03m# open URLs\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m728\u001b[39m ioargs = \u001b[43m_get_filepath_or_buffer\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    729\u001b[39m \u001b[43m    \u001b[49m\u001b[43mpath_or_buf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    730\u001b[39m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m=\u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    731\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcompression\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    732\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    733\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    734\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    736\u001b[39m handle = ioargs.filepath_or_buffer\n\u001b[32m    737\u001b[39m handles: \u001b[38;5;28mlist\u001b[39m[BaseBuffer]\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\HOANG MINH\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\pandas\\io\\common.py:384\u001b[39m, in \u001b[36m_get_filepath_or_buffer\u001b[39m\u001b[34m(filepath_or_buffer, encoding, compression, mode, storage_options)\u001b[39m\n\u001b[32m    382\u001b[39m \u001b[38;5;66;03m# assuming storage_options is to be interpreted as headers\u001b[39;00m\n\u001b[32m    383\u001b[39m req_info = urllib.request.Request(filepath_or_buffer, headers=storage_options)\n\u001b[32m--> \u001b[39m\u001b[32m384\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[43murlopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43mreq_info\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m req:\n\u001b[32m    385\u001b[39m     content_encoding = req.headers.get(\u001b[33m\"\u001b[39m\u001b[33mContent-Encoding\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[32m    386\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m content_encoding == \u001b[33m\"\u001b[39m\u001b[33mgzip\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m    387\u001b[39m         \u001b[38;5;66;03m# Override compression based on Content-Encoding header\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\HOANG MINH\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\pandas\\io\\common.py:289\u001b[39m, in \u001b[36murlopen\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    283\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    284\u001b[39m \u001b[33;03mLazy-import wrapper for stdlib urlopen, as that imports a big chunk of\u001b[39;00m\n\u001b[32m    285\u001b[39m \u001b[33;03mthe stdlib.\u001b[39;00m\n\u001b[32m    286\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    287\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01murllib\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mrequest\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m289\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43murllib\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m.\u001b[49m\u001b[43murlopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\HOANG MINH\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\urllib\\request.py:189\u001b[39m, in \u001b[36murlopen\u001b[39m\u001b[34m(url, data, timeout, context)\u001b[39m\n\u001b[32m    187\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    188\u001b[39m     opener = _opener\n\u001b[32m--> \u001b[39m\u001b[32m189\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mopener\u001b[49m\u001b[43m.\u001b[49m\u001b[43mopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\HOANG MINH\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\urllib\\request.py:495\u001b[39m, in \u001b[36mOpenerDirector.open\u001b[39m\u001b[34m(self, fullurl, data, timeout)\u001b[39m\n\u001b[32m    493\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m processor \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m.process_response.get(protocol, []):\n\u001b[32m    494\u001b[39m     meth = \u001b[38;5;28mgetattr\u001b[39m(processor, meth_name)\n\u001b[32m--> \u001b[39m\u001b[32m495\u001b[39m     response = \u001b[43mmeth\u001b[49m\u001b[43m(\u001b[49m\u001b[43mreq\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mresponse\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    497\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m response\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\HOANG MINH\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\urllib\\request.py:604\u001b[39m, in \u001b[36mHTTPErrorProcessor.http_response\u001b[39m\u001b[34m(self, request, response)\u001b[39m\n\u001b[32m    601\u001b[39m \u001b[38;5;66;03m# According to RFC 2616, \"2xx\" code indicates that the client's\u001b[39;00m\n\u001b[32m    602\u001b[39m \u001b[38;5;66;03m# request was successfully received, understood, and accepted.\u001b[39;00m\n\u001b[32m    603\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[32m200\u001b[39m <= code < \u001b[32m300\u001b[39m):\n\u001b[32m--> \u001b[39m\u001b[32m604\u001b[39m     response = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mparent\u001b[49m\u001b[43m.\u001b[49m\u001b[43merror\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    605\u001b[39m \u001b[43m        \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mhttp\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mresponse\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmsg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhdrs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    607\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m response\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\HOANG MINH\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\urllib\\request.py:533\u001b[39m, in \u001b[36mOpenerDirector.error\u001b[39m\u001b[34m(self, proto, *args)\u001b[39m\n\u001b[32m    531\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m http_err:\n\u001b[32m    532\u001b[39m     args = (\u001b[38;5;28mdict\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mdefault\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mhttp_error_default\u001b[39m\u001b[33m'\u001b[39m) + orig_args\n\u001b[32m--> \u001b[39m\u001b[32m533\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_chain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\HOANG MINH\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\urllib\\request.py:466\u001b[39m, in \u001b[36mOpenerDirector._call_chain\u001b[39m\u001b[34m(self, chain, kind, meth_name, *args)\u001b[39m\n\u001b[32m    464\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m handler \u001b[38;5;129;01min\u001b[39;00m handlers:\n\u001b[32m    465\u001b[39m     func = \u001b[38;5;28mgetattr\u001b[39m(handler, meth_name)\n\u001b[32m--> \u001b[39m\u001b[32m466\u001b[39m     result = \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    467\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m result \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    468\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\HOANG MINH\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\urllib\\request.py:613\u001b[39m, in \u001b[36mHTTPDefaultErrorHandler.http_error_default\u001b[39m\u001b[34m(self, req, fp, code, msg, hdrs)\u001b[39m\n\u001b[32m    612\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mhttp_error_default\u001b[39m(\u001b[38;5;28mself\u001b[39m, req, fp, code, msg, hdrs):\n\u001b[32m--> \u001b[39m\u001b[32m613\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m HTTPError(req.full_url, code, msg, hdrs, fp)\n",
      "\u001b[31mHTTPError\u001b[39m: HTTP Error 404: Not Found"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# --- BÀI 3.9: LỌC VÀ SẮP XẾP DỮ LIỆU EURO 2012 ---\n",
    "\n",
    "# Để code chạy được ngay mà không cần file,\n",
    "# ta đọc dữ liệu trực tiếp từ 1 link online\n",
    "url = 'https://raw.githubusercontent.com/guipsamora/pandas_exercises/master/02_Filtering_%26_Sorting/Euro_2012/Euro_2012_stats.csv'\n",
    "\n",
    "# \"Tạo data frame euro12\" (Đọc file)\n",
    "euro12 = pd.read_csv(url)\n",
    "print(\"--- Đã đọc dữ liệu euro2012.csv ---\")\n",
    "\n",
    "\n",
    "# 1. In giá trị cột Goals\n",
    "print(\"\\n1. Giá trị cột 'Goals':\")\n",
    "print(euro12['Goals'])\n",
    "\n",
    "# 2. Có bao nhiêu đội tham gia Euro2012?\n",
    "# Lấy số hàng (mỗi hàng 1 đội)\n",
    "num_teams = euro12.shape[0]\n",
    "print(f\"\\n2. Số đội tham gia: {num_teams} đội\")\n",
    "\n",
    "# 3. In thông tin của Euro2012 (type, shape, danh sách cột)\n",
    "print(\"\\n3. Thông tin chung của Euro2012:\")\n",
    "print(f\"   Kích thước (Shape): {euro12.shape}\")\n",
    "print(f\"   Danh sách các cột: {euro12.columns.tolist()}\")\n",
    "print(\"   Thông tin chi tiết (Info):\")\n",
    "euro12.info()\n",
    "\n",
    "# 4. Tạo 1 data frame mới discipline\n",
    "discipline = euro12[['Team', 'Yellow Cards', 'Red Cards']]\n",
    "print(\"\\n4. Data frame 'discipline' (5 dòng đầu):\")\n",
    "print(discipline.head())\n",
    "\n",
    "# 5. Sắp xếp discipline\n",
    "discipline_sorted = discipline.sort_values(by=['Red Cards', 'Yellow Cards'], ascending=False)\n",
    "print(\"\\n5. Discipline đã sắp xếp (Thẻ Đỏ, Thẻ Vàng giảm dần):\")\n",
    "print(discipline_sorted)\n",
    "\n",
    "# 6. a) Tính trung bình Yellow Cards\n",
    "avg_yellow_cards = euro12['Yellow Cards'].mean()\n",
    "print(f\"\\n6. a) Số thẻ vàng trung bình: {avg_yellow_cards:.2f}\")\n",
    "\n",
    "# 6. b) Lọc các đội đã ghi hơn 6 bàn thắng\n",
    "teams_over_6_goals = euro12[euro12['Goals'] > 6]\n",
    "print(\"\\n6. b) Các đội ghi hơn 6 bàn:\")\n",
    "print(teams_over_6_goals[['Team', 'Goals']])\n",
    "\n",
    "# 7. In các đội mà tên bắt đầu bằng 'G'\n",
    "teams_starting_G = euro12[euro12['Team'].str.startswith('G')]\n",
    "print(\"\\n7. Các đội có tên bắt đầu bằng 'G':\")\n",
    "print(teams_starting_G)\n",
    "\n",
    "# 8. In 7 cột đầu của euro12\n",
    "print(\"\\n8. 7 cột đầu tiên (5 dòng đầu):\")\n",
    "print(euro12.iloc[:, :7].head())\n",
    "\n",
    "# 9. In tất cả các cột, trừ 3 cột cuối\n",
    "print(\"\\n9. Tất cả các cột trừ 3 cột cuối (5 dòng đầu):\")\n",
    "print(euro12.iloc[:, :-3].head())\n",
    "\n",
    "# 10. In các cột Team, Goals, Shooting Accuracy, Yellow Cards, Red Cards\n",
    "selected_stats = euro12[['Team', 'Goals', 'Shooting Accuracy', 'Yellow Cards', 'Red Cards']]\n",
    "print(\"\\n10. Các cột (Team, Goals, Shooting Accuracy, YC, RC):\")\n",
    "print(selected_stats)\n",
    "\n",
    "# 11. In cột 'Team', 'Shooting Accuracy' của 'England', 'Italy', 'Russia'\n",
    "teams_of_interest = ['England', 'Italy', 'Russia']\n",
    "# Dùng .isin() để lọc các đội có trong list\n",
    "result_11 = euro12[euro12['Team'].isin(teams_of_interest)]\n",
    "print(\"\\n11. Shooting Accuracy của Anh, Ý, Nga:\")\n",
    "print(result_11[['Team', 'Shooting Accuracy']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "33c5cecf",
   "metadata": {},
   "outputs": [
    {
     "ename": "HTTPError",
     "evalue": "HTTP Error 404: Not Found",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mHTTPError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[12]\u001b[39m\u001b[32m, line 10\u001b[39m\n\u001b[32m      7\u001b[39m url = \u001b[33m'\u001b[39m\u001b[33mhttps://raw.githubusercontent.com/guipsamora/pandas_exercises/master/02_Filtering_\u001b[39m\u001b[33m%\u001b[39m\u001b[33m26_Sorting/Euro_2012/Euro_2012_stats.csv\u001b[39m\u001b[33m'\u001b[39m\n\u001b[32m      9\u001b[39m \u001b[38;5;66;03m# \"Tạo data frame euro12\" (Đọc file)\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m10\u001b[39m euro12 = \u001b[43mpd\u001b[49m\u001b[43m.\u001b[49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[43murl\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     11\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33m--- Đã đọc dữ liệu euro2012.csv ---\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     14\u001b[39m \u001b[38;5;66;03m# 1. In giá trị cột Goals\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\HOANG MINH\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1026\u001b[39m, in \u001b[36mread_csv\u001b[39m\u001b[34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[39m\n\u001b[32m   1013\u001b[39m kwds_defaults = _refine_defaults_read(\n\u001b[32m   1014\u001b[39m     dialect,\n\u001b[32m   1015\u001b[39m     delimiter,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1022\u001b[39m     dtype_backend=dtype_backend,\n\u001b[32m   1023\u001b[39m )\n\u001b[32m   1024\u001b[39m kwds.update(kwds_defaults)\n\u001b[32m-> \u001b[39m\u001b[32m1026\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\HOANG MINH\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:620\u001b[39m, in \u001b[36m_read\u001b[39m\u001b[34m(filepath_or_buffer, kwds)\u001b[39m\n\u001b[32m    617\u001b[39m _validate_names(kwds.get(\u001b[33m\"\u001b[39m\u001b[33mnames\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[32m    619\u001b[39m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m620\u001b[39m parser = \u001b[43mTextFileReader\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    622\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[32m    623\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\HOANG MINH\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1620\u001b[39m, in \u001b[36mTextFileReader.__init__\u001b[39m\u001b[34m(self, f, engine, **kwds)\u001b[39m\n\u001b[32m   1617\u001b[39m     \u001b[38;5;28mself\u001b[39m.options[\u001b[33m\"\u001b[39m\u001b[33mhas_index_names\u001b[39m\u001b[33m\"\u001b[39m] = kwds[\u001b[33m\"\u001b[39m\u001b[33mhas_index_names\u001b[39m\u001b[33m\"\u001b[39m]\n\u001b[32m   1619\u001b[39m \u001b[38;5;28mself\u001b[39m.handles: IOHandles | \u001b[38;5;28;01mNone\u001b[39;00m = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1620\u001b[39m \u001b[38;5;28mself\u001b[39m._engine = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_make_engine\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mengine\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\HOANG MINH\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1880\u001b[39m, in \u001b[36mTextFileReader._make_engine\u001b[39m\u001b[34m(self, f, engine)\u001b[39m\n\u001b[32m   1878\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mb\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[32m   1879\u001b[39m         mode += \u001b[33m\"\u001b[39m\u001b[33mb\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m-> \u001b[39m\u001b[32m1880\u001b[39m \u001b[38;5;28mself\u001b[39m.handles = \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1881\u001b[39m \u001b[43m    \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1882\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1883\u001b[39m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mencoding\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1884\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mcompression\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1885\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmemory_map\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmemory_map\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1886\u001b[39m \u001b[43m    \u001b[49m\u001b[43mis_text\u001b[49m\u001b[43m=\u001b[49m\u001b[43mis_text\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1887\u001b[39m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mencoding_errors\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstrict\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1888\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstorage_options\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1889\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1890\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m.handles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1891\u001b[39m f = \u001b[38;5;28mself\u001b[39m.handles.handle\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\HOANG MINH\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\pandas\\io\\common.py:728\u001b[39m, in \u001b[36mget_handle\u001b[39m\u001b[34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[39m\n\u001b[32m    725\u001b[39m     codecs.lookup_error(errors)\n\u001b[32m    727\u001b[39m \u001b[38;5;66;03m# open URLs\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m728\u001b[39m ioargs = \u001b[43m_get_filepath_or_buffer\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    729\u001b[39m \u001b[43m    \u001b[49m\u001b[43mpath_or_buf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    730\u001b[39m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m=\u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    731\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcompression\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    732\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    733\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    734\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    736\u001b[39m handle = ioargs.filepath_or_buffer\n\u001b[32m    737\u001b[39m handles: \u001b[38;5;28mlist\u001b[39m[BaseBuffer]\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\HOANG MINH\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\pandas\\io\\common.py:384\u001b[39m, in \u001b[36m_get_filepath_or_buffer\u001b[39m\u001b[34m(filepath_or_buffer, encoding, compression, mode, storage_options)\u001b[39m\n\u001b[32m    382\u001b[39m \u001b[38;5;66;03m# assuming storage_options is to be interpreted as headers\u001b[39;00m\n\u001b[32m    383\u001b[39m req_info = urllib.request.Request(filepath_or_buffer, headers=storage_options)\n\u001b[32m--> \u001b[39m\u001b[32m384\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[43murlopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43mreq_info\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m req:\n\u001b[32m    385\u001b[39m     content_encoding = req.headers.get(\u001b[33m\"\u001b[39m\u001b[33mContent-Encoding\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[32m    386\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m content_encoding == \u001b[33m\"\u001b[39m\u001b[33mgzip\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m    387\u001b[39m         \u001b[38;5;66;03m# Override compression based on Content-Encoding header\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\HOANG MINH\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\pandas\\io\\common.py:289\u001b[39m, in \u001b[36murlopen\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    283\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    284\u001b[39m \u001b[33;03mLazy-import wrapper for stdlib urlopen, as that imports a big chunk of\u001b[39;00m\n\u001b[32m    285\u001b[39m \u001b[33;03mthe stdlib.\u001b[39;00m\n\u001b[32m    286\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    287\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01murllib\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mrequest\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m289\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43murllib\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m.\u001b[49m\u001b[43murlopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\HOANG MINH\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\urllib\\request.py:189\u001b[39m, in \u001b[36murlopen\u001b[39m\u001b[34m(url, data, timeout, context)\u001b[39m\n\u001b[32m    187\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    188\u001b[39m     opener = _opener\n\u001b[32m--> \u001b[39m\u001b[32m189\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mopener\u001b[49m\u001b[43m.\u001b[49m\u001b[43mopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\HOANG MINH\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\urllib\\request.py:495\u001b[39m, in \u001b[36mOpenerDirector.open\u001b[39m\u001b[34m(self, fullurl, data, timeout)\u001b[39m\n\u001b[32m    493\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m processor \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m.process_response.get(protocol, []):\n\u001b[32m    494\u001b[39m     meth = \u001b[38;5;28mgetattr\u001b[39m(processor, meth_name)\n\u001b[32m--> \u001b[39m\u001b[32m495\u001b[39m     response = \u001b[43mmeth\u001b[49m\u001b[43m(\u001b[49m\u001b[43mreq\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mresponse\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    497\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m response\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\HOANG MINH\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\urllib\\request.py:604\u001b[39m, in \u001b[36mHTTPErrorProcessor.http_response\u001b[39m\u001b[34m(self, request, response)\u001b[39m\n\u001b[32m    601\u001b[39m \u001b[38;5;66;03m# According to RFC 2616, \"2xx\" code indicates that the client's\u001b[39;00m\n\u001b[32m    602\u001b[39m \u001b[38;5;66;03m# request was successfully received, understood, and accepted.\u001b[39;00m\n\u001b[32m    603\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[32m200\u001b[39m <= code < \u001b[32m300\u001b[39m):\n\u001b[32m--> \u001b[39m\u001b[32m604\u001b[39m     response = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mparent\u001b[49m\u001b[43m.\u001b[49m\u001b[43merror\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    605\u001b[39m \u001b[43m        \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mhttp\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mresponse\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmsg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhdrs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    607\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m response\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\HOANG MINH\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\urllib\\request.py:533\u001b[39m, in \u001b[36mOpenerDirector.error\u001b[39m\u001b[34m(self, proto, *args)\u001b[39m\n\u001b[32m    531\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m http_err:\n\u001b[32m    532\u001b[39m     args = (\u001b[38;5;28mdict\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mdefault\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mhttp_error_default\u001b[39m\u001b[33m'\u001b[39m) + orig_args\n\u001b[32m--> \u001b[39m\u001b[32m533\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_chain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\HOANG MINH\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\urllib\\request.py:466\u001b[39m, in \u001b[36mOpenerDirector._call_chain\u001b[39m\u001b[34m(self, chain, kind, meth_name, *args)\u001b[39m\n\u001b[32m    464\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m handler \u001b[38;5;129;01min\u001b[39;00m handlers:\n\u001b[32m    465\u001b[39m     func = \u001b[38;5;28mgetattr\u001b[39m(handler, meth_name)\n\u001b[32m--> \u001b[39m\u001b[32m466\u001b[39m     result = \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    467\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m result \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    468\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\HOANG MINH\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\urllib\\request.py:613\u001b[39m, in \u001b[36mHTTPDefaultErrorHandler.http_error_default\u001b[39m\u001b[34m(self, req, fp, code, msg, hdrs)\u001b[39m\n\u001b[32m    612\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mhttp_error_default\u001b[39m(\u001b[38;5;28mself\u001b[39m, req, fp, code, msg, hdrs):\n\u001b[32m--> \u001b[39m\u001b[32m613\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m HTTPError(req.full_url, code, msg, hdrs, fp)\n",
      "\u001b[31mHTTPError\u001b[39m: HTTP Error 404: Not Found"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# --- BÀI 3.9: LỌC VÀ SẮP XẾP DỮ LIỆU EURO 2012 ---\n",
    "\n",
    "# Để code chạy được ngay mà không cần file,\n",
    "# ta đọc dữ liệu trực tiếp từ 1 link online\n",
    "url = 'https://raw.githubusercontent.com/guipsamora/pandas_exercises/master/02_Filtering_%26_Sorting/Euro_2012/Euro_2012_stats.csv'\n",
    "\n",
    "# \"Tạo data frame euro12\" (Đọc file)\n",
    "euro12 = pd.read_csv(url)\n",
    "print(\"--- Đã đọc dữ liệu euro2012.csv ---\")\n",
    "\n",
    "\n",
    "# 1. In giá trị cột Goals\n",
    "print(\"\\n1. Giá trị cột 'Goals':\")\n",
    "print(euro12['Goals'])\n",
    "\n",
    "# 2. Có bao nhiêu đội tham gia Euro2012?\n",
    "# Lấy số hàng (mỗi hàng 1 đội)\n",
    "num_teams = euro12.shape[0]\n",
    "print(f\"\\n2. Số đội tham gia: {num_teams} đội\")\n",
    "\n",
    "# 3. In thông tin của Euro2012 (type, shape, danh sách cột)\n",
    "print(\"\\n3. Thông tin chung của Euro2012:\")\n",
    "print(f\"   Kích thước (Shape): {euro12.shape}\")\n",
    "print(f\"   Danh sách các cột: {euro12.columns.tolist()}\")\n",
    "print(\"   Thông tin chi tiết (Info):\")\n",
    "euro12.info()\n",
    "\n",
    "# 4. Tạo 1 data frame mới discipline\n",
    "discipline = euro12[['Team', 'Yellow Cards', 'Red Cards']]\n",
    "print(\"\\n4. Data frame 'discipline' (5 dòng đầu):\")\n",
    "print(discipline.head())\n",
    "\n",
    "# 5. Sắp xếp discipline\n",
    "discipline_sorted = discipline.sort_values(by=['Red Cards', 'Yellow Cards'], ascending=False)\n",
    "print(\"\\n5. Discipline đã sắp xếp (Thẻ Đỏ, Thẻ Vàng giảm dần):\")\n",
    "print(discipline_sorted)\n",
    "\n",
    "# 6. a) Tính trung bình Yellow Cards\n",
    "avg_yellow_cards = euro12['Yellow Cards'].mean()\n",
    "print(f\"\\n6. a) Số thẻ vàng trung bình: {avg_yellow_cards:.2f}\")\n",
    "\n",
    "# 6. b) Lọc các đội đã ghi hơn 6 bàn thắng\n",
    "teams_over_6_goals = euro12[euro12['Goals'] > 6]\n",
    "print(\"\\n6. b) Các đội ghi hơn 6 bàn:\")\n",
    "print(teams_over_6_goals[['Team', 'Goals']])\n",
    "\n",
    "# 7. In các đội mà tên bắt đầu bằng 'G'\n",
    "teams_starting_G = euro12[euro12['Team'].str.startswith('G')]\n",
    "print(\"\\n7. Các đội có tên bắt đầu bằng 'G':\")\n",
    "print(teams_starting_G)\n",
    "\n",
    "# 8. In 7 cột đầu của euro12\n",
    "print(\"\\n8. 7 cột đầu tiên (5 dòng đầu):\")\n",
    "print(euro12.iloc[:, :7].head())\n",
    "\n",
    "# 9. In tất cả các cột, trừ 3 cột cuối\n",
    "print(\"\\n9. Tất cả các cột trừ 3 cột cuối (5 dòng đầu):\")\n",
    "print(euro12.iloc[:, :-3].head())\n",
    "\n",
    "# 10. In các cột Team, Goals, Shooting Accuracy, Yellow Cards, Red Cards\n",
    "selected_stats = euro12[['Team', 'Goals', 'Shooting Accuracy', 'Yellow Cards', 'Red Cards']]\n",
    "print(\"\\n10. Các cột (Team, Goals, Shooting Accuracy, YC, RC):\")\n",
    "print(selected_stats)\n",
    "\n",
    "# 11. In cột 'Team', 'Shooting Accuracy' của 'England', 'Italy', 'Russia'\n",
    "teams_of_interest = ['England', 'Italy', 'Russia']\n",
    "# Dùng .isin() để lọc các đội có trong list\n",
    "result_11 = euro12[euro12['Team'].isin(teams_of_interest)]\n",
    "print(\"\\n11. Shooting Accuracy của Anh, Ý, Nga:\")\n",
    "print(result_11[['Team', 'Shooting Accuracy']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "aac16bed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "LỖI: Không thể tải hoặc xử lý dữ liệu. HTTP Error 404: Not Found\n",
      "Vui lòng kiểm tra kết nối Internet.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# --- BÀI 3.10: THỐNG KÊ DỮ LIỆU - GROUPBY ---\n",
    "\n",
    "# Đọc file drinks.csv từ một link online\n",
    "# (index_col=0: Dùng cột đầu tiên, 'country', làm chỉ mục)\n",
    "try:\n",
    "    url = \"https://raw.githubusercontent.com/guipsamora/pandas_exercises/master/03_Grouping/Alcohol_Consumption/drinks.csv\"\n",
    "    \n",
    "    # 1. Đọc dữ liệu, lưu vào biến 'drink'\n",
    "    drink = pd.read_csv(url, index_col=0)\n",
    "    print(\"--- 1. Đã đọc xong file 'drinks.csv' ---\")\n",
    "\n",
    "    # o Cho biết kiểu dữ liệu (type), kích thước (shape) của drink\n",
    "    print(\"\\nKiểu dữ liệu (dtypes):\")\n",
    "    print(drink.dtypes)\n",
    "    print(\"\\nKích thước (shape):\", drink.shape)\n",
    "    \n",
    "    # o Hiển thị tên các cột (columns) của drink\n",
    "    print(\"\\nTên các cột (columns):\", drink.columns.tolist())\n",
    "\n",
    "    # o Xem 5 dòng dữ liệu đầu (head) và cuối (tail)\n",
    "    print(\"\\n5 dòng đầu (head):\")\n",
    "    print(drink.head())\n",
    "    print(\"\\n5 dòng cuối (tail):\")\n",
    "    print(drink.tail())\n",
    "    \n",
    "    # 2. Cho biết số lượng bia tiêu thụ trung bình ở mỗi châu lục\n",
    "    print(\"\\n--- 2. Lượng bia TB theo châu lục ---\")\n",
    "    # Ta nhóm theo 'continent', chọn cột 'beer_servings' và tính trung bình\n",
    "    beer_mean = drink.groupby('continent')['beer_servings'].mean()\n",
    "    print(beer_mean)\n",
    "\n",
    "    # 3. Cho biết thông tin thống kê (describe) lượng rượu vang\n",
    "    print(\"\\n--- 3. Thống kê rượu vang theo châu lục ---\")\n",
    "    wine_stats = drink.groupby('continent')['wine_servings'].describe()\n",
    "    print(wine_stats)\n",
    "\n",
    "    # 4. Cho biết giá trị trung bình (mean), trung vị (median),\n",
    "    # min, max của rượu mạnh (spirit_servings)\n",
    "    print(\"\\n--- 4. Thống kê rượu mạnh theo châu lục ---\")\n",
    "    spirit_agg = drink.groupby('continent')['spirit_servings'].agg(\n",
    "        ['mean', 'median', 'min', 'max']\n",
    "    )\n",
    "    print(spirit_agg)\n",
    "    \n",
    "    # 5. Cho biết lượng (bia) trung bình lớn nhất ở châu lục\n",
    "    print(\"\\n--- 5. Châu lục uống bia TB nhiều nhất ---\")\n",
    "    # idxmax() tìm chỉ mục (tên châu lục) có giá trị lớn nhất\n",
    "    print(f\"Châu lục: {beer_mean.idxmax()}\")\n",
    "    print(f\"Lượng TB: {beer_mean.max():.2f} servings\")\n",
    "\n",
    "    # 6. Sắp xếp dữ liệu (sort_values) theo lượng bia tiêu thụ\n",
    "    print(\"\\n--- 6. Sắp xếp theo lượng bia giảm dần (Top 5) ---\")\n",
    "    drink_sorted_by_beer = drink.sort_values(by='beer_servings', ascending=False)\n",
    "    # In 5 dòng đầu của bảng đã sắp xếp\n",
    "    print(drink_sorted_by_beer.head())\n",
    "\n",
    "    # 7. Cho biết 5 quốc gia có lượng tiêu thụ bia nhiều nhất\n",
    "    print(\"\\n--- 7. 5 quốc gia uống bia nhiều nhất ---\")\n",
    "    # Dùng nlargest để lấy 5 giá trị lớn nhất\n",
    "    top_5_beer = drink.nlargest(5, 'beer_servings')\n",
    "    print(top_5_beer[['beer_servings']]) # Chỉ in cột bia\n",
    "\n",
    "    # 8. Cho biết 5 quốc gia có lượng tiêu thụ bia ít nhất\n",
    "    print(\"\\n--- 8. 5 quốc gia uống bia ít nhất ---\")\n",
    "    # Dùng nsmallest để lấy 5 giá trị nhỏ nhất\n",
    "    bottom_5_beer = drink.nsmallest(5, 'beer_servings')\n",
    "    print(bottom_5_beer[['beer_servings']])\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"\\nLỖI: Không thể tải hoặc xử lý dữ liệu. {e}\")\n",
    "    print(\"Vui lòng kiểm tra kết nối Internet.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7e55de1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 1. Đã đọc thành công 3 file CSV ---\n",
      "Thông tin stocks1:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 4 entries, 0 to 3\n",
      "Data columns (total 7 columns):\n",
      " #   Column  Non-Null Count  Dtype  \n",
      "---  ------  --------------  -----  \n",
      " 0   date    4 non-null      object \n",
      " 1   symbol  4 non-null      object \n",
      " 2   open    4 non-null      int64  \n",
      " 3   high    4 non-null      int64  \n",
      " 4   low     3 non-null      float64\n",
      " 5   close   4 non-null      int64  \n",
      " 6   volume  4 non-null      int64  \n",
      "dtypes: float64(1), int64(4), object(2)\n",
      "memory usage: 356.0+ bytes\n",
      "\n",
      "--- 2. Xử lý giá trị Null ---\n",
      "Đã xử lý xong giá trị Null.\n",
      "\n",
      "--- 3. Gộp stocks1 và stocks2 ---\n",
      "DataFrame 'stocks' sau khi gộp:\n",
      "         date symbol    open  high     low  close  volume\n",
      "0  2020-01-01   AAPL   150.0   152   149.0    151  1000.0\n",
      "1  2020-01-02   AAPL   151.0   153   150.0    152  1200.0\n",
      "2  2020-01-01   MSFT   200.0   202   198.0    199   800.0\n",
      "3  2020-01-02   MSFT   199.0   201   198.0    200   900.0\n",
      "4  2020-01-03   AAPL   153.0   155   152.0    154  1100.0\n",
      "5  2020-01-03   MSFT   201.0   203   200.0    202   850.0\n",
      "6  2020-01-01   GOOG  1000.0  1010   990.0   1005   500.0\n",
      "7  2020-01-02   GOOG     NaN   995  1000.0    600     NaN\n",
      "\n",
      "--- 4. Gộp stocks và companies ---\n",
      "5 dòng đầu của 'stocks_companies':\n",
      "         date symbol   open  high    low  close  volume  name  employees  \\\n",
      "0  2020-01-01   AAPL  150.0   152  149.0    151  1000.0  AAPL     150000   \n",
      "1  2020-01-02   AAPL  151.0   153  150.0    152  1200.0  AAPL     150000   \n",
      "2  2020-01-01   MSFT  200.0   202  198.0    199   800.0  MSFT     180000   \n",
      "3  2020-01-02   MSFT  199.0   201  198.0    200   900.0  MSFT     180000   \n",
      "4  2020-01-03   AAPL  153.0   155  152.0    154  1100.0  AAPL     150000   \n",
      "\n",
      "  headquarters_city headquarters_state  \n",
      "0         Cupertino         California  \n",
      "1         Cupertino         California  \n",
      "2           Redmond         Washington  \n",
      "3           Redmond         Washington  \n",
      "4         Cupertino         California  \n",
      "\n",
      "--- 5. Giá trị trung bình theo công ty ---\n",
      "             open         high         low       close  volume\n",
      "name                                                          \n",
      "AAPL   151.333333   153.333333  150.333333  152.333333  1100.0\n",
      "GOOG  1000.000000  1002.500000  995.000000  802.500000   500.0\n",
      "MSFT   200.000000   202.000000  198.666667  200.333333   850.0\n",
      "\n",
      "--- 6. Thống kê giá 'close' theo công ty ---\n",
      "            mean  min   max\n",
      "name                       \n",
      "AAPL  152.333333  151   154\n",
      "GOOG  802.500000  600  1005\n",
      "MSFT  200.333333  199   202\n",
      "\n",
      "--- 7. Đã tạo cột 'parsed_time' ---\n",
      "Kiểu dữ liệu cột 'parsed_time': datetime64[ns]\n",
      "\n",
      "--- 8. Đã thêm cột 'result' ---\n",
      "  symbol    open  close result\n",
      "0   AAPL   150.0    151     up\n",
      "1   AAPL   151.0    152     up\n",
      "2   MSFT   200.0    199   down\n",
      "3   MSFT   199.0    200     up\n",
      "4   AAPL   153.0    154     up\n",
      "5   MSFT   201.0    202     up\n",
      "6   GOOG  1000.0   1005     up\n",
      "7   GOOG     NaN    600   down\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# --- BÀI 3.11: GIAO DỊCH CHỨNG KHOÁN (ĐỌC FILE THẬT) ---\n",
    "\n",
    "try:\n",
    "    # 1. Đọc dữ liệu từ các file CSV\n",
    "    stocks1 = pd.read_csv('stocks1.csv')\n",
    "    stocks2 = pd.read_csv('stocks2.csv')\n",
    "    companies = pd.read_csv('companies.csv')\n",
    "\n",
    "    print(\"--- 1. Đã đọc thành công 3 file CSV ---\")\n",
    "    print(\"Thông tin stocks1:\")\n",
    "    stocks1.info()\n",
    "\n",
    "    # 2. Xử lý Null trong stocks1 và stocks2\n",
    "    print(\"\\n--- 2. Xử lý giá trị Null ---\")\n",
    "    \n",
    "    # Fill 'low' trong stocks1 bằng giá trị min của cột đó cho cùng mã 'symbol'\n",
    "    # transform trả về một Series có cùng index với DataFrame gốc\n",
    "    stocks1['low'] = stocks1.groupby('symbol')['low'].transform(lambda x: x.fillna(x.min()))\n",
    "    \n",
    "    # Fill 'high' trong stocks2 bằng giá trị max\n",
    "    stocks2['high'] = stocks2.groupby('symbol')['high'].transform(lambda x: x.fillna(x.max()))\n",
    "    print(\"Đã xử lý xong giá trị Null.\")\n",
    "\n",
    "    # 3. Gộp stocks1 và stocks2 thành stocks\n",
    "    stocks = pd.concat([stocks1, stocks2], ignore_index=True)\n",
    "    print(\"\\n--- 3. Gộp stocks1 và stocks2 ---\")\n",
    "    print(\"DataFrame 'stocks' sau khi gộp:\")\n",
    "    print(stocks)\n",
    "\n",
    "    # 4. Gộp stocks và companies thành stocks_companies\n",
    "    stocks_companies = pd.merge(stocks, companies, left_on='symbol', right_on='name')\n",
    "    print(\"\\n--- 4. Gộp stocks và companies ---\")\n",
    "    print(\"5 dòng đầu của 'stocks_companies':\")\n",
    "    print(stocks_companies.head())\n",
    "\n",
    "    # 5. Tính giá và volume trung bình của mỗi công ty\n",
    "    print(\"\\n--- 5. Giá trị trung bình theo công ty ---\")\n",
    "    cols_to_avg = ['open', 'high', 'low', 'close', 'volume']\n",
    "    company_avg = stocks_companies.groupby('name')[cols_to_avg].mean()\n",
    "    print(company_avg)\n",
    "\n",
    "    # 6. Thống kê giá đóng cửa (close)\n",
    "    print(\"\\n--- 6. Thống kê giá 'close' theo công ty ---\")\n",
    "    close_stats = stocks_companies.groupby('name')['close'].agg(['mean', 'min', 'max'])\n",
    "    print(close_stats)\n",
    "\n",
    "    # 7. Tạo cột parsed_time\n",
    "    stocks_companies['parsed_time'] = pd.to_datetime(stocks_companies['date'])\n",
    "    print(\"\\n--- 7. Đã tạo cột 'parsed_time' ---\")\n",
    "    print(\"Kiểu dữ liệu cột 'parsed_time':\", stocks_companies['parsed_time'].dtype)\n",
    "\n",
    "    # 8. Thêm cột result\n",
    "    stocks_companies['result'] = np.where(stocks_companies['close'] > stocks_companies['open'], 'up', 'down')\n",
    "    print(\"\\n--- 8. Đã thêm cột 'result' ---\")\n",
    "    print(stocks_companies[['symbol', 'open', 'close', 'result']])\n",
    "\n",
    "except FileNotFoundError:\n",
    "    print(\"LỖI: Không tìm thấy file CSV. Vui lòng đảm bảo bạn đã tạo các file\")\n",
    "    print(\"'stocks1.csv', 'stocks2.csv', và 'companies.csv' trong cùng thư mục.\")\n",
    "except Exception as e:\n",
    "    print(f\"Đã xảy ra lỗi: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "15fcc1c5",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyError\u001b[39m                                  Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32m<frozen importlib._bootstrap_external>:1512\u001b[39m, in \u001b[36m_path_importer_cache\u001b[39m\u001b[34m(cls, path)\u001b[39m\n",
      "\u001b[31mKeyError\u001b[39m: 'c:\\\\Users\\\\HOANG MINH\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python313\\\\Lib\\\\site-packages\\\\pandas\\\\core\\\\indexes'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpandas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpd\u001b[39;00m\n\u001b[32m      3\u001b[39m \u001b[38;5;66;03m# ------------------------------------------------------------------\u001b[39;00m\n\u001b[32m      4\u001b[39m \u001b[38;5;66;03m# ĐỊNH NGHĨA ĐƯỜNG DẪN\u001b[39;00m\n\u001b[32m      5\u001b[39m \u001b[38;5;66;03m# Giả sử các tệp CSV nằm trong thư mục con 'ml-latest-small'\u001b[39;00m\n\u001b[32m      6\u001b[39m \u001b[38;5;66;03m# ------------------------------------------------------------------\u001b[39;00m\n\u001b[32m      7\u001b[39m movies_path = \u001b[33m'\u001b[39m\u001b[33mml-latest-small/movies.csv\u001b[39m\u001b[33m'\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\HOANG MINH\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\pandas\\__init__.py:61\u001b[39m\n\u001b[32m     58\u001b[39m \u001b[38;5;66;03m# let init-time option registration happen\u001b[39;00m\n\u001b[32m     59\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpandas\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mcore\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mconfig_init\u001b[39;00m  \u001b[38;5;66;03m# pyright: ignore[reportUnusedImport] # noqa: F401\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m61\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpandas\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mcore\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mapi\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[32m     62\u001b[39m     \u001b[38;5;66;03m# dtype\u001b[39;00m\n\u001b[32m     63\u001b[39m     ArrowDtype,\n\u001b[32m     64\u001b[39m     Int8Dtype,\n\u001b[32m     65\u001b[39m     Int16Dtype,\n\u001b[32m     66\u001b[39m     Int32Dtype,\n\u001b[32m     67\u001b[39m     Int64Dtype,\n\u001b[32m     68\u001b[39m     UInt8Dtype,\n\u001b[32m     69\u001b[39m     UInt16Dtype,\n\u001b[32m     70\u001b[39m     UInt32Dtype,\n\u001b[32m     71\u001b[39m     UInt64Dtype,\n\u001b[32m     72\u001b[39m     Float32Dtype,\n\u001b[32m     73\u001b[39m     Float64Dtype,\n\u001b[32m     74\u001b[39m     CategoricalDtype,\n\u001b[32m     75\u001b[39m     PeriodDtype,\n\u001b[32m     76\u001b[39m     IntervalDtype,\n\u001b[32m     77\u001b[39m     DatetimeTZDtype,\n\u001b[32m     78\u001b[39m     StringDtype,\n\u001b[32m     79\u001b[39m     BooleanDtype,\n\u001b[32m     80\u001b[39m     \u001b[38;5;66;03m# missing\u001b[39;00m\n\u001b[32m     81\u001b[39m     NA,\n\u001b[32m     82\u001b[39m     isna,\n\u001b[32m     83\u001b[39m     isnull,\n\u001b[32m     84\u001b[39m     notna,\n\u001b[32m     85\u001b[39m     notnull,\n\u001b[32m     86\u001b[39m     \u001b[38;5;66;03m# indexes\u001b[39;00m\n\u001b[32m     87\u001b[39m     Index,\n\u001b[32m     88\u001b[39m     CategoricalIndex,\n\u001b[32m     89\u001b[39m     RangeIndex,\n\u001b[32m     90\u001b[39m     MultiIndex,\n\u001b[32m     91\u001b[39m     IntervalIndex,\n\u001b[32m     92\u001b[39m     TimedeltaIndex,\n\u001b[32m     93\u001b[39m     DatetimeIndex,\n\u001b[32m     94\u001b[39m     PeriodIndex,\n\u001b[32m     95\u001b[39m     IndexSlice,\n\u001b[32m     96\u001b[39m     \u001b[38;5;66;03m# tseries\u001b[39;00m\n\u001b[32m     97\u001b[39m     NaT,\n\u001b[32m     98\u001b[39m     Period,\n\u001b[32m     99\u001b[39m     period_range,\n\u001b[32m    100\u001b[39m     Timedelta,\n\u001b[32m    101\u001b[39m     timedelta_range,\n\u001b[32m    102\u001b[39m     Timestamp,\n\u001b[32m    103\u001b[39m     date_range,\n\u001b[32m    104\u001b[39m     bdate_range,\n\u001b[32m    105\u001b[39m     Interval,\n\u001b[32m    106\u001b[39m     interval_range,\n\u001b[32m    107\u001b[39m     DateOffset,\n\u001b[32m    108\u001b[39m     \u001b[38;5;66;03m# conversion\u001b[39;00m\n\u001b[32m    109\u001b[39m     to_numeric,\n\u001b[32m    110\u001b[39m     to_datetime,\n\u001b[32m    111\u001b[39m     to_timedelta,\n\u001b[32m    112\u001b[39m     \u001b[38;5;66;03m# misc\u001b[39;00m\n\u001b[32m    113\u001b[39m     Flags,\n\u001b[32m    114\u001b[39m     Grouper,\n\u001b[32m    115\u001b[39m     factorize,\n\u001b[32m    116\u001b[39m     unique,\n\u001b[32m    117\u001b[39m     value_counts,\n\u001b[32m    118\u001b[39m     NamedAgg,\n\u001b[32m    119\u001b[39m     array,\n\u001b[32m    120\u001b[39m     Categorical,\n\u001b[32m    121\u001b[39m     set_eng_float_format,\n\u001b[32m    122\u001b[39m     Series,\n\u001b[32m    123\u001b[39m     DataFrame,\n\u001b[32m    124\u001b[39m )\n\u001b[32m    126\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpandas\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mcore\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mdtypes\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mdtypes\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m SparseDtype\n\u001b[32m    128\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpandas\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mtseries\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mapi\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m infer_freq\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\HOANG MINH\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\pandas\\core\\api.py:47\u001b[39m\n\u001b[32m     45\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpandas\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mcore\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mconstruction\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m array\n\u001b[32m     46\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpandas\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mcore\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mflags\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Flags\n\u001b[32m---> \u001b[39m\u001b[32m47\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpandas\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mcore\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mgroupby\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[32m     48\u001b[39m     Grouper,\n\u001b[32m     49\u001b[39m     NamedAgg,\n\u001b[32m     50\u001b[39m )\n\u001b[32m     51\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpandas\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mcore\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mindexes\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mapi\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[32m     52\u001b[39m     CategoricalIndex,\n\u001b[32m     53\u001b[39m     DatetimeIndex,\n\u001b[32m   (...)\u001b[39m\u001b[32m     59\u001b[39m     TimedeltaIndex,\n\u001b[32m     60\u001b[39m )\n\u001b[32m     61\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpandas\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mcore\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mindexes\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mdatetimes\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[32m     62\u001b[39m     bdate_range,\n\u001b[32m     63\u001b[39m     date_range,\n\u001b[32m     64\u001b[39m )\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\HOANG MINH\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\pandas\\core\\groupby\\__init__.py:1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpandas\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mcore\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mgroupby\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mgeneric\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[32m      2\u001b[39m     DataFrameGroupBy,\n\u001b[32m      3\u001b[39m     NamedAgg,\n\u001b[32m      4\u001b[39m     SeriesGroupBy,\n\u001b[32m      5\u001b[39m )\n\u001b[32m      6\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpandas\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mcore\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mgroupby\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mgroupby\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m GroupBy\n\u001b[32m      7\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpandas\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mcore\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mgroupby\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mgrouper\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Grouper\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\HOANG MINH\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\pandas\\core\\groupby\\generic.py:68\u001b[39m\n\u001b[32m     60\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpandas\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mcore\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mapply\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[32m     61\u001b[39m     GroupByApply,\n\u001b[32m     62\u001b[39m     maybe_mangle_lambdas,\n\u001b[32m   (...)\u001b[39m\u001b[32m     65\u001b[39m     warn_alias_replacement,\n\u001b[32m     66\u001b[39m )\n\u001b[32m     67\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpandas\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mcore\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mcommon\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mcom\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m68\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpandas\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mcore\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mframe\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m DataFrame\n\u001b[32m     69\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpandas\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mcore\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mgroupby\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[32m     70\u001b[39m     base,\n\u001b[32m     71\u001b[39m     ops,\n\u001b[32m     72\u001b[39m )\n\u001b[32m     73\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpandas\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mcore\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mgroupby\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mgroupby\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[32m     74\u001b[39m     GroupBy,\n\u001b[32m     75\u001b[39m     GroupByPlot,\n\u001b[32m   (...)\u001b[39m\u001b[32m     79\u001b[39m     _transform_template,\n\u001b[32m     80\u001b[39m )\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\HOANG MINH\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\pandas\\core\\frame.py:153\u001b[39m\n\u001b[32m    147\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpandas\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mcore\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01marrays\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mstring_\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m StringDtype\n\u001b[32m    148\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpandas\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mcore\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mconstruction\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[32m    149\u001b[39m     ensure_wrapped_if_datetimelike,\n\u001b[32m    150\u001b[39m     sanitize_array,\n\u001b[32m    151\u001b[39m     sanitize_masked_array,\n\u001b[32m    152\u001b[39m )\n\u001b[32m--> \u001b[39m\u001b[32m153\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpandas\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mcore\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mgeneric\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[32m    154\u001b[39m     NDFrame,\n\u001b[32m    155\u001b[39m     make_doc,\n\u001b[32m    156\u001b[39m )\n\u001b[32m    157\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpandas\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mcore\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mindexers\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m check_key_length\n\u001b[32m    158\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpandas\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mcore\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mindexes\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mapi\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[32m    159\u001b[39m     DatetimeIndex,\n\u001b[32m    160\u001b[39m     Index,\n\u001b[32m   (...)\u001b[39m\u001b[32m    164\u001b[39m     ensure_index_from_sequences,\n\u001b[32m    165\u001b[39m )\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\HOANG MINH\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\pandas\\core\\generic.py:155\u001b[39m\n\u001b[32m    146\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpandas\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mcore\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mdtypes\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01minference\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[32m    147\u001b[39m     is_hashable,\n\u001b[32m    148\u001b[39m     is_nested_list_like,\n\u001b[32m    149\u001b[39m )\n\u001b[32m    150\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpandas\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mcore\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mdtypes\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mmissing\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[32m    151\u001b[39m     isna,\n\u001b[32m    152\u001b[39m     notna,\n\u001b[32m    153\u001b[39m )\n\u001b[32m--> \u001b[39m\u001b[32m155\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpandas\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mcore\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[32m    156\u001b[39m     algorithms \u001b[38;5;28;01mas\u001b[39;00m algos,\n\u001b[32m    157\u001b[39m     arraylike,\n\u001b[32m    158\u001b[39m     common,\n\u001b[32m    159\u001b[39m     indexing,\n\u001b[32m    160\u001b[39m     missing,\n\u001b[32m    161\u001b[39m     nanops,\n\u001b[32m    162\u001b[39m     sample,\n\u001b[32m    163\u001b[39m )\n\u001b[32m    164\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpandas\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mcore\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01marray_algos\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mreplace\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m should_use_regex\n\u001b[32m    165\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpandas\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mcore\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01marrays\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m ExtensionArray\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\HOANG MINH\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\pandas\\core\\indexing.py:80\u001b[39m\n\u001b[32m     70\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpandas\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mcore\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mconstruction\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[32m     71\u001b[39m     array \u001b[38;5;28;01mas\u001b[39;00m pd_array,\n\u001b[32m     72\u001b[39m     extract_array,\n\u001b[32m     73\u001b[39m )\n\u001b[32m     74\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpandas\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mcore\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mindexers\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[32m     75\u001b[39m     check_array_indexer,\n\u001b[32m     76\u001b[39m     is_list_like_indexer,\n\u001b[32m     77\u001b[39m     is_scalar_indexer,\n\u001b[32m     78\u001b[39m     length_of_indexer,\n\u001b[32m     79\u001b[39m )\n\u001b[32m---> \u001b[39m\u001b[32m80\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpandas\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mcore\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mindexes\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mapi\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[32m     81\u001b[39m     Index,\n\u001b[32m     82\u001b[39m     MultiIndex,\n\u001b[32m     83\u001b[39m )\n\u001b[32m     85\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m TYPE_CHECKING:\n\u001b[32m     86\u001b[39m     \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mcollections\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mabc\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[32m     87\u001b[39m         Hashable,\n\u001b[32m     88\u001b[39m         Sequence,\n\u001b[32m     89\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m<frozen importlib._bootstrap>:1360\u001b[39m, in \u001b[36m_find_and_load\u001b[39m\u001b[34m(name, import_)\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m<frozen importlib._bootstrap>:1322\u001b[39m, in \u001b[36m_find_and_load_unlocked\u001b[39m\u001b[34m(name, import_)\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m<frozen importlib._bootstrap>:1262\u001b[39m, in \u001b[36m_find_spec\u001b[39m\u001b[34m(name, path, target)\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m<frozen importlib._bootstrap_external>:1555\u001b[39m, in \u001b[36mfind_spec\u001b[39m\u001b[34m(cls, fullname, path, target)\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m<frozen importlib._bootstrap_external>:1527\u001b[39m, in \u001b[36m_get_spec\u001b[39m\u001b[34m(cls, fullname, path, target)\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m<frozen importlib._bootstrap_external>:1514\u001b[39m, in \u001b[36m_path_importer_cache\u001b[39m\u001b[34m(cls, path)\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m<frozen importlib._bootstrap_external>:1490\u001b[39m, in \u001b[36m_path_hooks\u001b[39m\u001b[34m(path)\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m<frozen zipimport>:79\u001b[39m, in \u001b[36m__init__\u001b[39m\u001b[34m(self, path)\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m<frozen importlib._bootstrap_external>:152\u001b[39m, in \u001b[36m_path_stat\u001b[39m\u001b[34m(path)\u001b[39m\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# ------------------------------------------------------------------\n",
    "# ĐỊNH NGHĨA ĐƯỜNG DẪN\n",
    "# Giả sử các tệp CSV nằm trong thư mục con 'ml-latest-small'\n",
    "# ------------------------------------------------------------------\n",
    "movies_path = 'ml-latest-small/movies.csv'\n",
    "ratings_path = 'ml-latest-small/ratings.csv'\n",
    "tags_path = 'ml-latest-small/tags.csv'\n",
    "\n",
    "print(\"Bắt đầu quá trình phân tích dữ liệu MovieLens...\")\n",
    "\n",
    "# ------------------------------------------------------------------\n",
    "# 1. Đọc dữ liệu & Data Structures\n",
    "# ------------------------------------------------------------------\n",
    "print(\"\\n--- 1. Đọc dữ liệu & Data Structures ---\")\n",
    "try:\n",
    "    # Đọc các tệp CSV vào DataFrame của pandas\n",
    "    movies_df = pd.read_csv(movies_path)\n",
    "    ratings_df = pd.read_csv(ratings_path)\n",
    "    tags_df = pd.read_csv(tags_path)\n",
    "\n",
    "    print(\"Đã đọc thành công 3 tệp CSV.\")\n",
    "    \n",
    "    print(\"\\nThông tin tệp 'movies.csv':\")\n",
    "    movies_df.info()\n",
    "    print(\"\\n5 dòng đầu tiên của 'movies.csv':\")\n",
    "    print(movies_df.head())\n",
    "\n",
    "    print(\"\\nThông tin tệp 'ratings.csv':\")\n",
    "    ratings_df.info()\n",
    "    print(\"\\n5 dòng đầu tiên của 'ratings.csv':\")\n",
    "    print(ratings_df.head())\n",
    "\n",
    "except FileNotFoundError:\n",
    "    print(f\"LỖI: Không tìm thấy tệp.\")\n",
    "    print(f\"Hãy chắc chắn rằng bạn đã giải nén tệp zip và\")\n",
    "    print(f\"đường dẫn '{movies_path}' là chính xác.\")\n",
    "    # Thoát chương trình nếu không tìm thấy tệp\n",
    "    exit()\n",
    "\n",
    "# ------------------------------------------------------------------\n",
    "# 2. Xử lý dữ liệu bị thiếu/không hợp lệ\n",
    "# ------------------------------------------------------------------\n",
    "print(\"\\n--- 2. Xử lý dữ liệu bị thiếu/không hợp lệ ---\")\n",
    "# Kiểm tra xem có bao nhiêu giá trị bị thiếu (NaN) trong mỗi cột\n",
    "print(\"Kiểm tra giá trị thiếu (NaN) trong 'movies_df':\")\n",
    "print(movies_df.isnull().sum())\n",
    "print(\"\\nKiểm tra giá trị thiếu (NaN) trong 'ratings_df':\")\n",
    "print(ratings_df.isnull().sum())\n",
    "\n",
    "# Bộ dữ liệu này khá sạch. \n",
    "# Nếu có dữ liệu thiếu, chúng ta có thể xóa các hàng đó:\n",
    "# movies_df = movies_df.dropna()\n",
    "# ratings_df = ratings_df.dropna()\n",
    "print(\"Bộ dữ liệu này không có giá trị nào bị thiếu.\")\n",
    "\n",
    "# ------------------------------------------------------------------\n",
    "# 3. Gộp DataFrame\n",
    "# ------------------------------------------------------------------\n",
    "print(\"\\n--- 3. Gộp DataFrame ---\")\n",
    "# Gộp (merge) ratings_df và movies_df dựa trên cột chung 'movieId'\n",
    "merged_df = pd.merge(ratings_df, movies_df, on='movieId')\n",
    "\n",
    "print(\"Đã gộp thành công 'ratings_df' và 'movies_df' dựa trên 'movieId'.\")\n",
    "print(\"5 dòng đầu tiên của DataFrame đã gộp:\")\n",
    "print(merged_df.head())\n",
    "\n",
    "# ------------------------------------------------------------------\n",
    "# 4. Lọc dữ liệu theo yêu cầu\n",
    "# ------------------------------------------------------------------\n",
    "print(\"\\n--- 4. Lọc dữ liệu theo yêu cầu ---\")\n",
    "# Ví dụ: Lọc tất cả các đánh giá cho một bộ phim cụ thể, \n",
    "# ví dụ 'Forrest Gump (1994)' (có movieId = 356)\n",
    "forrest_gump_ratings = merged_df[merged_df['title'] == 'Forrest Gump (1994)']\n",
    "print(f\"\\nTìm thấy {len(forrest_gump_ratings)} đánh giá cho phim 'Forrest Gump (1994)':\")\n",
    "print(forrest_gump_ratings[['userId', 'rating', 'timestamp']].head())\n",
    "\n",
    "# Ví dụ 2: Lọc tất cả các phim được đánh giá 5 sao\n",
    "top_rated_movies = merged_df[merged_df['rating'] == 5.0]\n",
    "print(f\"\\nTìm thấy {len(top_rated_movies)} lượt đánh giá 5 sao.\")\n",
    "print(\"Một số phim được đánh giá 5 sao:\")\n",
    "print(top_rated_movies[['title', 'genres', 'userId']].head())\n",
    "\n",
    "# ------------------------------------------------------------------\n",
    "# 5. Thống kê dữ liệu\n",
    "# ------------------------------------------------------------------\n",
    "print(\"\\n--- 5. Thống kê dữ liệu ---\")\n",
    "# Thống kê mô tả chung cho cột 'rating' (điểm đánh giá)\n",
    "print(\"Thống kê mô tả chung cho tất cả các đánh giá (cột 'rating'):\")\n",
    "print(merged_df['rating'].describe())\n",
    "\n",
    "# Tính điểm trung bình và số lượng đánh giá cho mỗi phim\n",
    "movie_stats = merged_df.groupby('title')['rating'].agg(['count', 'mean'])\n",
    "movie_stats = movie_stats.rename(columns={'count': 'Số lượng đánh giá', 'mean': 'Điểm trung bình'})\n",
    "\n",
    "# Sắp xếp theo điểm trung bình giảm dần\n",
    "print(\"\\nTop 10 phim có điểm trung bình cao nhất (với ít nhất 50 đánh giá):\")\n",
    "min_reviews = 50\n",
    "high_rated_popular = movie_stats[movie_stats['Số lượng đánh giá'] >= min_reviews]\n",
    "print(high_rated_popular.sort_values(by='Điểm trung bình', ascending=False).head(10))\n",
    "\n",
    "# Sắp xếp theo số lượng đánh giá giảm dần\n",
    "print(\"\\nTop 10 phim được đánh giá nhiều nhất:\")\n",
    "print(movie_stats.sort_values(by='Số lượng đánh giá', ascending=False).head(10))\n",
    "\n",
    "# ------------------------------------------------------------------\n",
    "# 6. Parsing Timestamps\n",
    "# ------------------------------------------------------------------\n",
    "print(\"\\n--- 6. Parsing Timestamps ---\")\n",
    "# Cột 'timestamp' hiện là một số nguyên (Unix timestamp)\n",
    "print(\"Kiểu dữ liệu của cột 'timestamp' trước khi chuyển đổi:\")\n",
    "print(ratings_df['timestamp'].dtype)\n",
    "print(ratings_df[['userId', 'timestamp']].head())\n",
    "\n",
    "# Chuyển đổi timestamp (đơn vị là giây) sang đối tượng datetime\n",
    "# Chúng ta sẽ tạo một cột mới tên là 'datetime'\n",
    "ratings_df['datetime'] = pd.to_datetime(ratings_df['timestamp'], unit='s')\n",
    "tags_df['datetime'] = pd.to_datetime(tags_df['timestamp'], unit='s')\n",
    "\n",
    "print(\"\\nĐã chuyển đổi 'timestamp' sang 'datetime' (trong ratings_df):\")\n",
    "print(ratings_df[['userId', 'timestamp', 'datetime']].head())\n",
    "\n",
    "print(\"\\nĐã chuyển đổi 'timestamp' sang 'datetime' (trong tags_df):\")\n",
    "print(tags_df[['userId', 'tag', 'datetime']].head())\n",
    "\n",
    "print(\"\\n--- Quá trình phân tích hoàn tất ---\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
